# üìÑ Definici√≥n de los Datos

## üß≠ Origen de los Datos

### Fuentes de datos principales

El proyecto **Diagn√≥stico Tributario Inteligente** se apoya en tres fuentes principales:

---

### 1. Datos Transaccionales

Conjunto de declaraciones tributarias reales en formato PDF, correspondientes a personas jur√≠dicas. Incluye:

- **Formulario 300** (Impuesto sobre las Ventas ‚Äì IVA)
- **Formulario 350** (Retenci√≥n en la Fuente)
- **Formulario 110** (Impuesto sobre la Renta)

Estos formularios constituyen los insumos primarios para la detecci√≥n de alertas tributarias, identificaci√≥n de inconsistencias y evaluaci√≥n de cumplimiento.

---

### 2. Base de Conocimiento Jur√≠dico

Repositorio de conocimiento jur√≠dico-tributario estructurado en archivos Markdown, que incluye:

- Jurisprudencia relevante
- Conceptos y pronunciamientos oficiales de la DIAN
- Extractos seleccionados de normativa tributaria

Esta base curada act√∫a como **fuente de verdad** para el agente de razonamiento, permitiendo explicar alertas y respaldarlas con normatividad vigente.

---

### 3. L√≥gica de Negocio

Plantillas de validaci√≥n en formato Excel que contienen:

- Reglas de negocio codificadas (e.g. plazos, cruces, saldos)
- Checklists tributarios
- Casos de referencia

Estas plantillas definen las validaciones clave que el motor del sistema debe replicar para emitir alertas y priorizar hallazgos.

---

## ‚öôÔ∏è M√©todo de Obtenci√≥n

Los datos se extraen a trav√©s de un pipeline propio de procesamiento de PDFs implementado en Python. Actualmente se utilizan las librer√≠as:

- `pdfplumber`
- `PyMuPDF`
- `re` (expresiones regulares)

El extractor transforma los formularios en texto estructurado y lo convierte en registros tabulares.  
Aunque en etapas futuras se contempla el uso de modelos como **SmolDocling** para formularios m√°s complejos, esta integraci√≥n a√∫n no ha sido implementada.

---

## üìú Especificaci√≥n de Scripts para la Carga de Datos

### Script principal de adquisici√≥n

- **Archivo**: `scripts/data_acquisition/main.py`  
- **Funci√≥n**: Procesa autom√°ticamente todos los archivos PDF de declaraciones tributarias

### M√≥dulo de procesamiento

- **Ubicaci√≥n**: `src/diagnostico_tributario/procesador.py`  
- **Funci√≥n clave**: `procesar_un_pdf()` ‚Äì Extrae texto y datos estructurados de cada formulario.

---

## üîÑ Pipeline de Procesamiento

El flujo implementado consta de las siguientes etapas:

1. **Extracci√≥n de texto**: Conversi√≥n del PDF a texto plano estructurado
2. **An√°lisis tributario**: Identificaci√≥n de tipo de formulario, NIT, per√≠odo, y valores monetarios clave
3. **Consolidaci√≥n**: Generaci√≥n de un √∫nico dataset estructurado en formato CSV
4. **Validaci√≥n**: Revisi√≥n de la calidad de extracci√≥n y presencia de campos clave

---

## üìÅ Rutas y Archivos

### Ubicaci√≥n de los archivos de origen
   data/raw/declaraciones_pdf/
   ‚îú‚îÄ‚îÄ iva.pdf          # Formulario 300 - IVA
   ‚îú‚îÄ‚îÄ renta.pdf        # Formulario 110 - Renta
   ‚îî‚îÄ‚îÄ Retefuente.pdf   # Formulario 350 - Retefuente

- **Formato**: PDF con texto seleccionable
- **Contenido**: Formularios oficiales de la DIAN diligenciados
- **Tama√±o promedio**: 3.000‚Äì5.000 caracteres por archivo

---

## üîß Transformaci√≥n y Limpieza

- **Extracci√≥n de texto**: Uso de m√∫ltiples librer√≠as para mayor compatibilidad
- **An√°lisis estructural**: Identificaci√≥n autom√°tica de patrones tributarios (e.g. ingresos, retenciones)
- **Validaci√≥n de calidad**: Comprobaci√≥n de completitud y coherencia de datos
- **Estandarizaci√≥n**: Conversi√≥n a formatos uniformes para fechas, montos y c√≥digos
- **Consolidaci√≥n**: Uni√≥n de todos los formularios en un √∫nico archivo CSV
- **Enriquecimiento**: C√°lculo de m√©tricas como n√∫mero de valores detectados, longitud de texto y calidad de extracci√≥n

---

## üì¶ Base de Datos de Destino

- **Ruta de salida**: `data/processed/declaraciones_consolidadas.csv`
- **Formato**: CSV con ~16 columnas estructuradas

### Principales campos:

- Metadatos del archivo: nombre, ruta, tama√±o, fecha
- Datos clave: NIT, tipo de declaraci√≥n, a√±o, per√≠odo
- Valores monetarios extra√≠dos
- M√©tricas de extracci√≥n: longitud del texto, valores identificados, calidad

---

## üéØ Criterios de Calidad Esperados

Dado el car√°cter protot√≠pico del sistema y la disponibilidad actual de datos reales (solo tres formularios), el objetivo principal es **validar la estructura, consistencia y funcionamiento del flujo de extracci√≥n**.

Los criterios definidos para futuras fases incluyen:

- **Precisi√≥n esperada de extracci√≥n**: ‚â• 95% en campos num√©ricos clave
- **Cobertura m√≠nima de reglas de validaci√≥n**: 15 reglas, una vez el sistema se escale a datos reales o sint√©ticos
- **Tiempo de procesamiento por archivo**: Menor a 3 minutos

---

## ‚ö†Ô∏è Nota Importante

Actualmente, el dataset incluye **√∫nicamente tres archivos reales** (uno por tipo de declaraci√≥n). Por tanto, **no es posible realizar an√°lisis exploratorio ni validar m√©tricas de desempe√±o generalizables**.  
Esta fase se enfoca en demostrar la viabilidad t√©cnica, la modularidad del sistema y la preparaci√≥n para escalar en futuras etapas con m√°s datos.
